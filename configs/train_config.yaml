# Architecture
hidden_size: 768
kg_embed_size: 256
num_attention_heads: 12
num_hidden_layers: 6
proj_dim: 512

# Tokenization
max_seq_len: 512
max_neighbors: 5
umls_path: "data/umls/2023AA"
kg_path: "data/kg/hetionet_subgraph.pkl"

# Training
batch_size: 32
learning_rate: 2e-5
temperature: 0.1
margin: 0.5
epochs: 20
max_grad_norm: 1.0

# Data Paths
data_dir: "data/mimic_processed"
relations_map: "data/umls/relations.csv"
